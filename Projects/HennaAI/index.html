<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Web Serial + Whisper + DALL·E Demo</title>
    <style>
      body {
        font-family: sans-serif;
        margin: 20px;
      }
      .status {
        margin-top: 10px;
        color: #555;
      }
      .container {
        text-align: center;
        margin-top: 30px;
      }
      #mainUI {
        display: none; /* Hidden until Arduino is connected */
      }
      .image-container {
        margin-top: 20px;
        max-width: 512px;
        margin: 20px auto;
      }
      .image-container img {
        max-width: 100%;
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
      }
    </style>
  </head>
  <body>
    <div style="text-align: center; margin-top: 30px">
      <button id="connectBtn">Connect to Arduino</button>
    </div>

    <div id="mainUI">
      <div class="container">
        <h2>Speech-to-Image Demo</h2>
        <!-- Status messages and transcribed text -->
        <div class="status" id="recordingStatus"></div>
        <div class="status" id="transcriptionText"></div>

        <!-- Container for the generated image -->
        <div id="imageResult" class="image-container"></div>
      </div>
    </div>

    <script type="module">
      /******************************************************
       * Import our dithering/byte-building logic here:
       ******************************************************/
      import { ditherImageData, buildImageBytes } from "./imageProcessing.js";

      /******************************************************
       * CONFIG / GLOBALS
       ******************************************************/
      // Replace with your actual API key
      // (If using in production, do NOT store it client-side)
      const OPENAI_API_KEY = "";

      let port;
      let writer;
      let reader;

      let isRecording = false;
      let mediaRecorder;
      let audioChunks = [];

      // DOM Elements
      const connectBtn = document.getElementById("connectBtn");
      const mainUI = document.getElementById("mainUI");
      const recordingStatusEl = document.getElementById("recordingStatus");
      const transcriptionTextEl = document.getElementById("transcriptionText");
      const imageResultEl = document.getElementById("imageResult");

      /******************************************************
       * 1. CONNECT TO ARDUINO
       ******************************************************/
      connectBtn.addEventListener("click", async () => {
        try {
          port = await navigator.serial.requestPort();
          await port.open({ baudRate: 9600 });
          writer = port.writable.getWriter();
          reader = port.readable.getReader();

          console.log("Port opened successfully.");
          mainUI.style.display = "block";

          // Start reading from the Arduino
          readLoop();
        } catch (err) {
          console.error("Failed to open port", err);
          alert("Failed to open port. Check your connection and permissions.");
        }
      });

      /******************************************************
       * 2. READ LOOP (Listen for "BUTTON_PRESSED")
       ******************************************************/
      async function readLoop() {
        while (true) {
          try {
            const { value, done } = await reader.read();
            if (done) {
              // If no more data, exit the loop
              break;
            }
            const message = new TextDecoder().decode(value).trim();
            console.log("Received from Arduino:", message);

            // If we detect a button press, toggle start/stop recording
            if (message === "pushed") {
              if (!isRecording) {
                startRecording();
              } else {
                stopRecording();
              }
            }
          } catch (err) {
            console.error("Error reading from serial:", err);
            break;
          }
        }
      }

      /******************************************************
       * 3. AUDIO RECORDING (start/stop) & WHISPER
       ******************************************************/
      async function startRecording() {
        recordingStatusEl.textContent = "Recording started...";
        transcriptionTextEl.textContent = "";
        imageResultEl.innerHTML = "";
        isRecording = true;
        audioChunks = [];

        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          mediaRecorder = new MediaRecorder(stream);

          mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
          };

          mediaRecorder.start();
        } catch (error) {
          console.error("Error accessing microphone:", error);
          recordingStatusEl.textContent =
            "Microphone error. Check permissions / HTTPS.";
        }
      }

      async function stopRecording() {
        recordingStatusEl.textContent = "Stopping recording...";
        isRecording = false;

        if (!mediaRecorder) return;

        // Handle audio once recorder stops
        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunks, { type: "audio/mp3" });
          try {
            // 4. Transcribe with Whisper
            const transcription = await transcribeAudio(audioBlob);
            const transcribedConversation = transcription.text || "";
            console.log("Transcribed text:", transcribedConversation);
            transcriptionTextEl.textContent = `Transcribed: "${transcribedConversation}"`;

            // --- NEW STEP: Summarize the conversation into a short prompt ---
            const shortSubjectPrompt = await getHennaPromptFromConversation(
              transcribedConversation
            );
            console.log("Refined prompt from GPT:", shortSubjectPrompt);

            // 5. Generate image with DALL·E
            //    (We attach GPT's "shortSubjectPrompt" to the existing basePrompt)
            const base64String = await generateImage(shortSubjectPrompt);

            // 6. Display the image
            imageResultEl.innerHTML = `<img src="data:image/png;base64,${base64String}" alt="Generated image">`;

            // 7. Dither and send image to Arduino
            await ditherAndSendImage(base64String);
            recordingStatusEl.textContent =
              "Image sent to Arduino. Waiting 20 seconds for printing...";

            // 8. Wait 20 seconds, then ready for next press
            await new Promise((resolve) => setTimeout(resolve, 20000));
            recordingStatusEl.textContent =
              "Ready. Press the button to record again.";
          } catch (err) {
            console.error("Error in transcription or image generation:", err);
            transcriptionTextEl.textContent = "Error: see console.";
          }
        };

        mediaRecorder.stop();
        // stop the tracks to release the microphone
        mediaRecorder.stream.getTracks().forEach((track) => track.stop());
      }

      // unchanged whisper call
      async function transcribeAudio(audioFile) {
        const formData = new FormData();
        formData.append("file", audioFile);
        formData.append("model", "whisper-1");

        const response = await fetch(
          "https://api.openai.com/v1/audio/transcriptions",
          {
            method: "POST",
            headers: {
              Authorization: `Bearer ${OPENAI_API_KEY}`,
            },
            body: formData,
          }
        );
        const data = await response.json();
        return data;
      }

      /******************************************************
       * 4. DALL·E IMAGE GENERATION
       ******************************************************/

      // For the sake of clarity, we've kept your original basePrompt
      const basePrompt =
        "A photo of a beautiful henna design on a hand. Includes patterns such as mandalas, flowers, and paisley motifs. Do not include all patterns in every design. Style is fine line work. Increase or decrease the size of the design depending on how much time is mentioned in the prompt. The design can be on the hand or fingers. Balanced composition. The design maintains a modern yet traditional aesthetic, suitable for events and celebrations. The background is neutral to highlight the intricate details of the henna art. About the subject, infer it from the next few sentences. Make sure the subject is always drawn on the hand. Subject: ";

      async function generateImage(shortSubjectPrompt) {
        // Combine base prompt + GPT's short subject prompt
        const dallEPrompt = `${basePrompt} ${shortSubjectPrompt}`;

        const response = await fetch(
          "https://api.openai.com/v1/images/generations",
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${OPENAI_API_KEY}`,
            },
            body: JSON.stringify({
              model: "dall-e-3",
              prompt: dallEPrompt,
              n: 1,
              size: "1024x1024",
              response_format: "b64_json",
            }),
          }
        );
        const data = await response.json();
        return data.data[0].b64_json; // The base64-encoded PNG
      }

      /******************************************************
       * 5. DITHER + SEND IMAGE TO ARDUINO
       ******************************************************/
      async function ditherAndSendImage(base64String) {
        return new Promise((resolve, reject) => {
          const img = new Image();
          img.crossOrigin = "anonymous";

          img.onload = async function () {
            try {
              const desiredWidth = 384;
              const aspectRatio = img.height / img.width;
              const desiredHeight = Math.round(desiredWidth * aspectRatio);

              const canvas = document.createElement("canvas");
              canvas.width = desiredWidth;
              canvas.height = desiredHeight;
              const ctx = canvas.getContext("2d");
              ctx.drawImage(img, 0, 0, desiredWidth, desiredHeight);

              // Perform dithering
              ditherImageData(ctx, desiredWidth, desiredHeight);

              // Convert to bytes
              const imageBytes = buildImageBytes(
                ctx,
                desiredWidth,
                desiredHeight
              );
              console.log("Image bytes ready:", imageBytes.length);

              // Send to Arduino
              await sendImageToArduino(imageBytes);
              resolve();
            } catch (err) {
              reject(err);
            }
          };

          img.onerror = reject;
          img.src = `data:image/png;base64,${base64String}`;
        });
      }

      async function sendImageToArduino(imageBytes) {
        if (!writer || !imageBytes) {
          alert("Not connected or no image to send!");
          return;
        }
        try {
          // Send length first (4 bytes, little-endian)
          const lengthBuffer = new Uint8Array(4);
          const len = imageBytes.length;
          lengthBuffer[0] = len & 0xff;
          lengthBuffer[1] = (len >> 8) & 0xff;
          lengthBuffer[2] = (len >> 16) & 0xff;
          lengthBuffer[3] = (len >> 24) & 0xff;
          await writer.write(lengthBuffer);

          // Send image data in 64-byte chunks
          const chunkSize = 64;
          for (let i = 0; i < imageBytes.length; i += chunkSize) {
            const chunk = imageBytes.slice(i, i + chunkSize);
            await writer.write(chunk);
            // a small delay can help
            await new Promise((r) => setTimeout(r, 10));
          }
          console.log("Image data sent to Arduino!");
        } catch (err) {
          console.error("Error sending data", err);
        }
      }

      /******************************************************
       * NEW FUNCTION: getHennaPromptFromConversation
       *  - Calls ChatGPT to extract a short subject prompt
       *    from the conversation between the henna artist
       *    and the client.
       ******************************************************/
      async function getHennaPromptFromConversation(conversationText) {
        try {
          // You can adjust the system or developer role message to match your usage
          const requestBody = {
            model: "gpt-4o", // or "gpt-3.5-turbo", "gpt-4", etc.
            messages: [
              {
                role: "system",
                content:
                  "You are a helpful assistant. Your goal is to read a conversation between a henna artist and a client, and produce a SHORT, concise phrase describing the central subject or theme that should be depicted in the final henna design. Do not include irrelevant details. Respond with just that short description.",
              },
              {
                role: "user",
                content: conversationText,
              },
            ],
          };

          const response = await fetch(
            "https://api.openai.com/v1/chat/completions",
            {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
                Authorization: `Bearer ${OPENAI_API_KEY}`,
              },
              body: JSON.stringify(requestBody),
            }
          );

          const data = await response.json();
          // The refined prompt is in data.choices[0].message.content
          return data.choices[0].message.content.trim();
        } catch (error) {
          console.error("Error calling ChatGPT:", error);
          // Fallback: if there's an error, just return the entire conversation
          return conversationText;
        }
      }
    </script>
  </body>
</html>
